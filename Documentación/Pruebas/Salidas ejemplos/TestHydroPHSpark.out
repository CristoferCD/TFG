2018-07-16 18:08:05 WARN  Utils:66 - Your hostname, localhost.localdomain resolves to a loopback address: 127.0.0.1; using 10.0.2.15 instead (on interface enp0s17)
2018-07-16 18:08:05 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2018-07-16 18:08:06 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 0) / 2][Stage 0:>                                                          (0 + 2) / 2][Stage 0:=============================>                             (1 + 1) / 2]                                                                                [Stage 2:>                                                          (0 + 2) / 2][Stage 2:=============================>                             (1 + 1) / 2]                                                                                [Stage 3:>                                                          (0 + 2) / 2][Stage 3:=============================>                             (1 + 1) / 2]                                                                                [Stage 4:>                                                          (0 + 2) / 2][Stage 4:=============================>                             (1 + 1) / 2]                                                                                [Stage 5:>                                                          (0 + 2) / 2][Stage 5:=============================>                             (1 + 1) / 2]                                                                                [Stage 6:>                                                          (0 + 2) / 2][Stage 6:=============================>                             (1 + 1) / 2]                                                                                [Stage 7:>                                                          (0 + 2) / 2][Stage 7:=============================>                             (1 + 1) / 2]                                                                                [Stage 8:>                                                          (0 + 2) / 2][Stage 8:=============================>                             (1 + 1) / 2]                                                                                [Stage 9:>                                                          (0 + 2) / 2][Stage 9:=============================>                             (1 + 1) / 2]                                                                                [Stage 10:>                                                         (0 + 2) / 2][Stage 10:=============================>                            (1 + 1) / 2]                                                                                [Stage 11:>                                                         (0 + 2) / 2][Stage 11:=============================>                            (1 + 1) / 2]                                                                                [Stage 12:>                                                         (0 + 2) / 2][Stage 12:=============================>                            (1 + 1) / 2]                                                                                [Stage 13:>                                                         (0 + 2) / 2][Stage 13:=============================>                            (1 + 1) / 2]                                                                                [Stage 14:>                                                         (0 + 2) / 2][Stage 14:=============================>                            (1 + 1) / 2]                                                                                [Stage 15:>                                                         (0 + 2) / 2][Stage 15:=============================>                            (1 + 1) / 2]                                                                                [Stage 16:>                                                         (0 + 2) / 2][Stage 16:=============================>                            (1 + 1) / 2]                                                                                [Stage 17:>                                                         (0 + 2) / 2][Stage 17:=============================>                            (1 + 1) / 2]                                                                                [Stage 18:>                                                         (0 + 2) / 2][Stage 18:=============================>                            (1 + 1) / 2]                                                                                [Stage 19:>                                                         (0 + 2) / 2][Stage 19:=============================>                            (1 + 1) / 2]                                                                                [Stage 20:>                                                         (0 + 2) / 2][Stage 20:=============================>                            (1 + 1) / 2]                                                                                [Stage 24:>                                                         (0 + 2) / 2][Stage 24:=============================>                            (1 + 1) / 2]                                                                                User-defined PH solution writer module=pyomo.pysp.plugins.jsonsolutionwriter already imported - skipping
User-defined PH extension module=pyomo.pysp.plugins.phhistoryextension already imported - skipping
Initializing PH

Overriding default variable transmission settings for PHPyro to transmit leaf-stage variable values at intermediate PH iterations.
Starting PH

Initiating PH iteration=0
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=      4.4363 Max-Min=   29.95
Converger=Normalized term diff value is         0.1411 - threshold reached=False
Cumulative run-time=0.74 seconds

Initiating PH iteration=1
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=      7.3098 Max-Min=   11.46
Converger=Normalized term diff value is         0.0727 - threshold reached=False
Cumulative run-time=4.79 seconds

Initiating PH iteration=2
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=     11.9422 Max-Min=   23.10
Converger=Normalized term diff value is         0.1385 - threshold reached=False
Cumulative run-time=8.36 seconds

Initiating PH iteration=3
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=     10.0703 Max-Min=    3.43
Converger=Normalized term diff value is         0.0142 - threshold reached=False
Cumulative run-time=11.78 seconds

Initiating PH iteration=4
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=     11.0317 Max-Min=    3.10
Converger=Normalized term diff value is         0.0156 - threshold reached=False
Cumulative run-time=15.18 seconds

Initiating PH iteration=5
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=     11.7254 Max-Min=    2.38
Converger=Normalized term diff value is         0.0173 - threshold reached=False
Cumulative run-time=18.64 seconds

Initiating PH iteration=6
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=     12.1719 Max-Min=    2.21
Converger=Normalized term diff value is         0.0180 - threshold reached=False
Cumulative run-time=22.23 seconds

Initiating PH iteration=7
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=     12.4769 Max-Min=    0.74
Converger=Normalized term diff value is         0.0028 - threshold reached=False
Cumulative run-time=25.56 seconds

Initiating PH iteration=8
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=     12.6846 Max-Min=    0.68
Converger=Normalized term diff value is         0.0023 - threshold reached=False
Cumulative run-time=29.12 seconds

Initiating PH iteration=9
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=     12.8029 Max-Min=    0.58
Converger=Normalized term diff value is         0.0023 - threshold reached=False
Cumulative run-time=32.51 seconds

Initiating PH iteration=10
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=     12.9223 Max-Min=    0.31
Converger=Normalized term diff value is         0.0014 - threshold reached=False
Cumulative run-time=35.86 seconds

Initiating PH iteration=11
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=     13.0652 Max-Min=    0.14
Converger=Normalized term diff value is         0.0005 - threshold reached=False
Cumulative run-time=39.44 seconds

Initiating PH iteration=12
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=     13.1787 Max-Min=    0.29
Converger=Normalized term diff value is         0.0006 - threshold reached=False
Cumulative run-time=42.81 seconds

Initiating PH iteration=13
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=     13.2570 Max-Min=    0.42
Converger=Normalized term diff value is         0.0008 - threshold reached=False
Cumulative run-time=46.24 seconds

Initiating PH iteration=14
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=     13.3062 Max-Min=    0.43
Converger=Normalized term diff value is         0.0008 - threshold reached=False
Cumulative run-time=49.63 seconds

Initiating PH iteration=15
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=     13.3535 Max-Min=    0.05
Converger=Normalized term diff value is         0.0002 - threshold reached=False
Cumulative run-time=53.16 seconds

Initiating PH iteration=16
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=     13.3898 Max-Min=    0.04
Converger=Normalized term diff value is         0.0002 - threshold reached=False
Cumulative run-time=56.45 seconds

Initiating PH iteration=17
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=     13.4208 Max-Min=    0.03
Converger=Normalized term diff value is         0.0002 - threshold reached=False
Cumulative run-time=59.56 seconds

Initiating PH iteration=18
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=     13.4488 Max-Min=    0.02
Converger=Normalized term diff value is         0.0001 - threshold reached=False
Cumulative run-time=62.93 seconds

Initiating PH iteration=19
Number of discrete variables fixed=0 (total=0)
Number of continuous variables fixed=0 (total=16)
First stage cost avg=     13.4748 Max-Min=    0.01
Converger=Normalized term diff value is         0.0001 - threshold reached=True
Cumulative run-time=66.28 seconds

Number of discrete variables fixed before final plugin calls=0 (total=0)
Number of continuous variables fixed before final plugin calls=0 (total=16)
PH algorithm history written to file=ph_history.json
PH complete

Convergence history:
Converger=Normalized term diff
Iteration    Metric Value
     0               0.1411
     1               0.0727
     2               0.1385
     3               0.0142
     4               0.0156
     5               0.0173
     6               0.0180
     7               0.0028
     8               0.0023
     9               0.0023
    10               0.0014
    11               0.0005
    12               0.0006
    13               0.0008
    14               0.0008
    15               0.0002
    16               0.0002
    17               0.0002
    18               0.0001
    19               0.0001


Final number of discrete variables fixed=0 (total=0)
Final number of continuous variables fixed=0 (total=16)

Computing objective inner bound at xhat solution
At least one sub-problem solve time was undefined - skipping timing statistics
At least one sub-problem solve time was undefined - skipping timing statistics
 ** At least one sub-problem failed to solve! ** 
 Failed sub-problems:
   Scen1
   Scen2
   Scen3
   Scen7
   Scen8
   Scen9

Failed to compute bound at xhat due to one or more solve failures. Restoring PH to solution at final iteration.
Generating scenario tree solution from scenario averages

Scenario tree variable values:

   Stage: FirstStage
          (Scenarios: Scen1  Scen2  Scen3  Scen4  Scen5  Scen6  Scen7  Scen8  Scen9  )
          (Scenarios: Scen1  Scen2  Scen3  Scen4  Scen5  Scen6  Scen7  Scen8  Scen9  )
      Variable: Pgh
         Index: [1]	Values:       76.4981     76.4981     76.4981     76.4985     76.5086     76.5086     76.4984     76.4984     76.4984

          (Scenarios: Scen1  Scen2  Scen3  Scen4  Scen5  Scen6  Scen7  Scen8  Scen9  )
      Variable: Pgt
         Index: [1]	Values:       13.5019     13.5019     13.50192018-07-16 18:09:34 WARN  TaskSetManager:66 - Lost task 0.0 in stage 25.0 (TID 50, 10.0.2.15, executor 0): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 229, in main
    process()
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 224, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 2438, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 2438, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 2438, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 362, in func
    return f(iterator)
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 1056, in <lambda>
    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 1056, in <genexpr>
    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()
  File "/media/sf_GitHub/TFG/pyomo/pyomo/solvers/plugins/smanager/phspark.py", line 95, in <lambda>
    self._rddWorkerList = self._rddWorkerList.map(lambda worker: _do_parallel_bulk(worker, task_dict))
  File "/media/sf_GitHub/TFG/pyomo/pyomo/solvers/plugins/smanager/phspark.py", line 88, in _do_parallel_bulk
    worker.process(task)
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/work/app-20180716180808-0261/0/phsolverserver.py", line 137, in process
    result = self._solver_server.process(data)
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/work/app-20180716180808-0261/0/phsolverserver.py", line 1367, in process
    data.release_cache)
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/work/app-20180716180808-0261/0/phsolverserver.py", line 1181, in restoreCachedSolutions
    _PHBase.restoreCachedSolutions(self, cache_id, release_cache)
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/ph.py", line 467, in restoreCachedSolutions
    % (cache_id))
RuntimeError: PH scenario tree solution cache with id 33555d9b-6f58-4ef7-b9cc-027e55a8257a does not exist

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

[Stage 25:>                                                         (0 + 2) / 2]2018-07-16 18:09:40 ERROR TaskSetManager:70 - Task 0 in stage 25.0 failed 4 times; aborting job
[Stage 25:>                                                         (0 + 1) / 2]2018-07-16 18:09:40 WARN  TaskSetManager:66 - Lost task 1.3 in stage 25.0 (TID 56, 10.0.2.15, executor 0): TaskKilled (Stage cancelled)
[Stage 26:>                                                         (0 + 2) / 2]2018-07-16 18:09:42 WARN  TaskSetManager:66 - Lost task 1.0 in stage 26.0 (TID 59, 10.0.2.15, executor 0): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 229, in main
    process()
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 224, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 2438, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 2438, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 2438, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 362, in func
    return f(iterator)
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 1056, in <lambda>
    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 1056, in <genexpr>
    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()
  File "/media/sf_GitHub/TFG/pyomo/pyomo/solvers/plugins/smanager/phspark.py", line 95, in <lambda>
    self._rddWorkerList = self._rddWorkerList.map(lambda worker: _do_parallel_bulk(worker, task_dict))
  File "/media/sf_GitHub/TFG/pyomo/pyomo/solvers/plugins/smanager/phspark.py", line 88, in _do_parallel_bulk
    worker.process(task)
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/work/app-20180716180808-0261/0/phsolverserver.py", line 137, in process
    result = self._solver_server.process(data)
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/work/app-20180716180808-0261/0/phsolverserver.py", line 1367, in process
    data.release_cache)
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/work/app-20180716180808-0261/0/phsolverserver.py", line 1181, in restoreCachedSolutions
    _PHBase.restoreCachedSolutions(self, cache_id, release_cache)
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/ph.py", line 467, in restoreCachedSolutions
    % (cache_id))
RuntimeError: PH scenario tree solution cache with id 33555d9b-6f58-4ef7-b9cc-027e55a8257a does not exist

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2018-07-16 18:09:47 ERROR TaskSetManager:70 - Task 1 in stage 26.0 failed 4 times; aborting job
     13.5015     13.4914     13.4914     13.5016     13.5016     13.5016

          (Scenarios: Scen1  Scen2  Scen3  Scen4  Scen5  Scen6  Scen7  Scen8  Scen9  )
      Variable: Vol
         Index: [1]	Values:       44.4539     44.4539     44.4539     44.4537     44.4476     44.4476     44.4538     44.4538     44.4538

      Cost Variable: StageCost[1]
         Tree Node: RootNode      (Scenarios:  Scen1 Scen2 Scen3 Scen4 Scen5 Scen6 Scen7 Scen8 Scen9 )
         Values:       13.4772     13.4772     13.4772     13.4768     13.4668     13.4668     13.4770     13.4770     13.4770    Max-Min:        0.0105   Avg:       13.4748
   Stage: SecondStage
          (Scenarios: Scen1  Scen2  Scen3  )
          (Scenarios: Scen4  Scen5  Scen6  )
          (Scenarios: Scen7  Scen8  Scen9  )
          (Scenarios: Scen1  Scen2  Scen3  )
      Variable: Pgh
         Index: [2]
         Tree Node: Node2_1	Values:       60.0000     60.0000     60.0000

          (Scenarios: Scen4  Scen5  Scen6  )
         Index: [2]
         Tree Node: Node2_2	Values:       83.2562     83.2682     83.2682

          (Scenarios: Scen7  Scen8  Scen9  )
         Index: [2]
         Tree Node: Node2_3	Values:      100.0000    100.0000    100.0000

          (Scenarios: Scen1  Scen2  Scen3  )
      Variable: Pgt
         Index: [2]
         Tree Node: Node2_1	Values:      100.0000    100.0000    100.0000

          (Scenarios: Scen4  Scen5  Scen6  )
         Index: [2]
         Tree Node: Node2_2	Values:       76.7438     76.7318     76.7318

          (Scenarios: Scen7  Scen8  Scen9  )
         Index: [2]
         Tree Node: Node2_3	Values:       60.0000     60.0000     60.0000

          (Scenarios: Scen1  Scen2  Scen3  )
      Variable: Vol
         Index: [2]
         Tree Node: Node2_1	Values:       14.2139     14.2139     14.2139

          (Scenarios: Scen4  Scen5  Scen6  )
         Index: [2]
         Tree Node: Node2_2	Values:       24.1920     24.3270     24.3270

          (Scenarios: Scen7  Scen8  Scen9  )
         Index: [2]
         Tree Node: Node2_3	Values:       38.4058     38.4058     38.4058

      Cost Variable: StageCost[2]
         Tree Node: Node2_1      (Scenarios:  Scen1 Scen2 Scen3 )
         Values:       99.8174     99.8174     99.8174    Max-Min:        0.0000   Avg:       99.8174
         Tree Node: Node2_2      (Scenarios:  Scen4 Scen5 Scen6 )
         Values:       76.6036     76.5917     76.5917    Max-Min:        0.0119   Avg:       76.5957
         Tree Node: Node2_3      (Scenarios:  Scen7 Scen8 Scen9 )
         Values:       59.8904     59.8904     59.8904    Max-Min:        0.0000   Avg:       59.8904
Scenario tree costs:
Scenario Tree Costs
----------------------------------------------------
Tree Nodes:

	Name=Node2_1
	Stage=SecondStage
	Parent=RootNode
	Conditional probability=0.3330
	Children:
		Node3_1_1
		Node3_1_2
		Node3_1_3
	Scenarios:
		Scen1
		Scen2
		Scen3
	Expected cost of (sub)tree rooted at node=  222.3302

	Name=Node2_2
	Stage=SecondStage
	Parent=RootNode
	Conditional probability=0.3330
	Children:
		Node3_2_1
		Node3_2_2
		Node3_2_3
	Scenarios:
		Scen4
		Scen5
		Scen6
	Expected cost of (sub)tree rooted at node=  166.1911

	Name=Node2_3
	Stage=SecondStage
	Parent=RootNode
	Conditional probability=0.3340
	Children:
		Node3_3_1
		Node3_3_2
		Node3_3_3
	Scenarios:
		Scen7
		Scen8
		Scen9
	Expected cost of (sub)tree rooted at node=  137.8441

	Name=Node3_1_1
	Stage=ThirdStage
	Parent=Node2_1
	Conditional probability=0.3330
	Children:
		None
	Scenarios:
		Scen1
	Expected cost of (sub)tree rooted at node=  181.8247

	Name=Node3_1_2
	Stage=ThirdStage
	Parent=Node2_1
	Conditional probability=0.3330
	Children:
		None
	Scenarios:
		Scen2
	Expected cost of (sub)tree rooted at node=   97.8905

	Name=Node3_1_3
	Stage=ThirdStage
	Parent=Node2_1
	Conditional probability=0.3340
	Children:
		None
	Scenarios:
		Scen3
	Expected cost of (sub)tree rooted at node=   87.9270

	Name=Node3_2_1
	Stage=ThirdStage
	Parent=Node2_2
	Conditional probability=0.3330
	Children:
		None
	Scenarios:
		Scen4
	Expected cost of (sub)tree rooted at node=   99.6351

	Name=Node3_2_2
	Stage=ThirdStage
	Parent=Node2_2
	Conditional probability=0.3330
	Children:
		None
	Scenarios:
		Scen5
	Expected cost of (sub)tree rooted at node=   89.5604

	Name=Node3_2_3
	Stage=ThirdStage
	Parent=Node2_2
	Conditional probability=0.3340
	Children:
		None
	Scenarios:
		Scen6
	Expected cost of (sub)tree rooted at node=   79.5969

	Name=Node3_3_1
	Stage=ThirdStage
	Parent=Node2_3
	Conditional probability=0.3330
	Children:
		None
	Scenarios:
		Scen7
	Expected cost of (sub)tree rooted at node=   87.9272

	Name=Node3_3_2
	Stage=ThirdStage
	Parent=Node2_3
	Conditional probability=0.3330
	Children:
		None
	Scenarios:
		Scen8
	Expected cost of (sub)tree rooted at node=   77.9637

	Name=Node3_3_3
	Stage=ThirdStage
	Parent=Node2_3
	Conditional probability=0.3340
	Children:
		None
	Scenarios:
		Scen9
	Expected cost of (sub)tree rooted at node=   68.0001

	Name=RootNode
	Stage=FirstStage
	Parent=None
	Conditional probability=1.0000
	Children:
		Node2_1
		Node2_2
		Node2_3
	Scenarios:
		Scen1
		Scen2
		Scen3
		Scen4
		Scen5
		Scen6
		Scen7
		Scen8
		Scen9
	Expected cost of (sub)tree rooted at node=  188.8947

----------------------------------------------------
Scenarios:

	Name=Scen1
	Probability=0.1109
	Leaf Node=Node3_1_1
	Tree node sequence:
		RootNode
		Node2_1
		Node3_1_1
	Stage=          FirstStage     Cost=   13.4772
	Stage=         SecondStage     Cost=   99.8174
	Stage=          ThirdStage     Cost=  181.8247
	Total scenario cost=  295.1193

	Name=Scen2
	Probability=0.1109
	Leaf Node=Node3_1_2
	Tree node sequence:
		RootNode
		Node2_1
		Node3_1_2
	Stage=          FirstStage     Cost=   13.4772
	Stage=         SecondStage     Cost=   99.8174
	Stage=          ThirdStage     Cost=   97.8905
	Total scenario cost=  211.1851

	Name=Scen3
	Probability=0.1112
	Leaf Node=Node3_1_3
	Tree node sequence:
		RootNode
		Node2_1
		Node3_1_3
	Stage=          FirstStage     Cost=   13.4772
	Stage=         SecondStage     Cost=   99.8174
	Stage=          ThirdStage     Cost=   87.9270
	Total scenario cost=  201.2216

	Name=Scen4
	Probability=0.1109
	Leaf Node=Node3_2_1
	Tree node sequence:
		RootNode
		Node2_2
		Node3_2_1
	Stage=          FirstStage     Cost=   13.4768
	Stage=         SecondStage     Cost=   76.6036
	Stage=          ThirdStage     Cost=   99.6351
	Total scenario cost=  189.7156

	Name=Scen5
	Probability=0.1109
	Leaf Node=Node3_2_2
	Tree node sequence:
		RootNode
		Node2_2
		Node3_2_2
	Stage=          FirstStage     Cost=   13.4668
	Stage=         SecondStage     Cost=   76.5917
	Stage=          ThirdStage     Cost=   89.5604
	Total scenario cost=  179.6188

	Name=Scen6
	Probability=0.1112
	Leaf Node=Node3_2_3
	Tree node sequence:
		RootNode
		Node2_2
		Node3_2_3
	Stage=          FirstStage     Cost=   13.4668
	Stage=         SecondStage     Cost=   76.5917
	Stage=          ThirdStage     Cost=   79.5969
	Total scenario cost=  169.6553

	Name=Scen7
	Probability=0.1112
	Leaf Node=Node3_3_1
	Tree node sequence:
		RootNode
		Node2_3
		Node3_3_1
	Stage=          FirstStage     Cost=   13.4770
	Stage=         SecondStage     Cost=   59.8904
	Stage=          ThirdStage     Cost=   87.9272
	Total scenario cost=  161.2946

	Name=Scen8
	Probability=0.1112
	Leaf Node=Node3_3_2
	Tree node sequence:
		RootNode
		Node2_3
		Node3_3_2
	Stage=          FirstStage     Cost=   13.4770
	Stage=         SecondStage     Cost=   59.8904
	Stage=          ThirdStage     Cost=   77.9637
	Total scenario cost=  151.3310

	Name=Scen9
	Probability=0.1116
	Leaf Node=Node3_3_3
	Tree node sequence:
		RootNode
		Node2_3
		Node3_3_3
	Stage=          FirstStage     Cost=   13.4770
	Stage=         SecondStage     Cost=   59.8904
	Stage=          ThirdStage     Cost=   68.0001
	Total scenario cost=  141.3675

----------------------------------------------------


Total PH execution time=70.23 seconds

Scenario tree solution written to file=ph_solution.json
Traceback (most recent call last):
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/phinit.py", line 992, in PHFromScratchManagedContext
    yield ph
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/phinit.py", line 1288, in exec_runph
    run_ph(options, ph)
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/phinit.py", line 1204, in run_ph
    ph.release_components()
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/ph.py", line 1233, in release_components
    phsolverserverutils.release_phsolverservers(self)
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/phsolverserverutils.py", line 394, in release_phsolverservers
    ph._solver_manager.end_bulk(True)
  File "/media/sf_GitHub/TFG/pyomo/pyomo/solvers/plugins/smanager/phspark.py", line 99, in end_bulk
    self._rddWorkerList.count()
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 1056, in count
    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 1047, in sum
    return self.mapPartitions(lambda x: [sum(x)]).fold(0, operator.add)
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 921, in fold
    vals = self.mapPartitions(func).collect()
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 824, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/py4j/java_gateway.py", line 1160, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/py4j/protocol.py", line 320, in get_return_value
    format(target_id, ".", name), value)
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 25.0 failed 4 times, most recent failure: Lost task 0.3 in stage 25.0 (TID 57, 10.0.2.15, executor 0): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 229, in main
    process()
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 224, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 2438, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 2438, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 2438, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 362, in func
    return f(iterator)
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 1056, in <lambda>
    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 1056, in <genexpr>
    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()
  File "/media/sf_GitHub/TFG/pyomo/pyomo/solvers/plugins/smanager/phspark.py", line 95, in <lambda>
    self._rddWorkerList = self._rddWorkerList.map(lambda worker: _do_parallel_bulk(worker, task_dict))
  File "/media/sf_GitHub/TFG/pyomo/pyomo/solvers/plugins/smanager/phspark.py", line 88, in _do_parallel_bulk
    worker.process(task)
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/work/app-20180716180808-0261/0/phsolverserver.py", line 137, in process
    result = self._solver_server.process(data)
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/work/app-20180716180808-0261/0/phsolverserver.py", line 1367, in process
    data.release_cache)
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/work/app-20180716180808-0261/0/phsolverserver.py", line 1181, in restoreCachedSolutions
    _PHBase.restoreCachedSolutions(self, cache_id, release_cache)
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/ph.py", line 467, in restoreCachedSolutions
    % (cache_id))
RuntimeError: PH scenario tree solution cache with id 33555d9b-6f58-4ef7-b9cc-027e55a8257a does not exist

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:938)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:153)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 229, in main
    process()
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 224, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 2438, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 2438, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 2438, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 362, in func
    return f(iterator)
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 1056, in <lambda>
    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 1056, in <genexpr>
    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()
  File "/media/sf_GitHub/TFG/pyomo/pyomo/solvers/plugins/smanager/phspark.py", line 95, in <lambda>
    self._rddWorkerList = self._rddWorkerList.map(lambda worker: _do_parallel_bulk(worker, task_dict))
  File "/media/sf_GitHub/TFG/pyomo/pyomo/solvers/plugins/smanager/phspark.py", line 88, in _do_parallel_bulk
    worker.process(task)
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/work/app-20180716180808-0261/0/phsolverserver.py", line 137, in process
    result = self._solver_server.process(data)
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/work/app-20180716180808-0261/0/phsolverserver.py", line 1367, in process
    data.release_cache)
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/work/app-20180716180808-0261/0/phsolverserver.py", line 1181, in restoreCachedSolutions
    _PHBase.restoreCachedSolutions(self, cache_id, release_cache)
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/ph.py", line 467, in restoreCachedSolutions
    % (cache_id))
RuntimeError: PH scenario tree solution cache with id 33555d9b-6f58-4ef7-b9cc-027e55a8257a does not exist

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/crist/python-venv/pyomo3/bin/runph", line 11, in <module>
    load_entry_point('Pyomo', 'console_scripts', 'runph')()
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/phinit.py", line 1354, in PH_main
    return main(args=args)
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/phinit.py", line 1349, in main
    traceback=options.traceback)
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/util/misc.py", line 344, in launch_command
    rc = command(options, *cmd_args, **cmd_kwds)
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/phinit.py", line 1288, in exec_runph
    run_ph(options, ph)
  File "/usr/lib64/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/phinit.py", line 996, in PHFromScratchManagedContext
    PHCleanup(ph)
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/phinit.py", line 1003, in PHCleanup
    ph.release_components()
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/ph.py", line 1233, in release_components
    phsolverserverutils.release_phsolverservers(self)
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/phsolverserverutils.py", line 394, in release_phsolverservers
    ph._solver_manager.end_bulk(True)
  File "/media/sf_GitHub/TFG/pyomo/pyomo/solvers/plugins/smanager/phspark.py", line 99, in end_bulk
    self._rddWorkerList.count()
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 1056, in count
    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 1047, in sum
    return self.mapPartitions(lambda x: [sum(x)]).fold(0, operator.add)
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 921, in fold
    vals = self.mapPartitions(func).collect()
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 824, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/py4j/java_gateway.py", line 1160, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/py4j/protocol.py", line 320, in get_return_value
    format(target_id, ".", name), value)
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 26.0 failed 4 times, most recent failure: Lost task 1.3 in stage 26.0 (TID 64, 10.0.2.15, executor 0): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 229, in main
    process()
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 224, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 2438, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 2438, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 2438, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 362, in func
    return f(iterator)
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 1056, in <lambda>
    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 1056, in <genexpr>
    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()
  File "/media/sf_GitHub/TFG/pyomo/pyomo/solvers/plugins/smanager/phspark.py", line 95, in <lambda>
    self._rddWorkerList = self._rddWorkerList.map(lambda worker: _do_parallel_bulk(worker, task_dict))
  File "/media/sf_GitHub/TFG/pyomo/pyomo/solvers/plugins/smanager/phspark.py", line 88, in _do_parallel_bulk
    worker.process(task)
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/work/app-20180716180808-0261/0/phsolverserver.py", line 137, in process
    result = self._solver_server.process(data)
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/work/app-20180716180808-0261/0/phsolverserver.py", line 1367, in process
    data.release_cache)
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/work/app-20180716180808-0261/0/phsolverserver.py", line 1181, in restoreCachedSolutions
    _PHBase.restoreCachedSolutions(self, cache_id, release_cache)
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/ph.py", line 467, in restoreCachedSolutions
    % (cache_id))
RuntimeError: PH scenario tree solution cache with id 33555d9b-6f58-4ef7-b9cc-027e55a8257a does not exist

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:938)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:153)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.GeneratedMethodAccessor40.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 229, in main
    process()
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 224, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 2438, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 2438, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 2438, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 362, in func
    return f(iterator)
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 1056, in <lambda>
    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()
  File "/home/crist/python-venv/pyomo3/lib64/python3.6/site-packages/pyspark/rdd.py", line 1056, in <genexpr>
    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()
  File "/media/sf_GitHub/TFG/pyomo/pyomo/solvers/plugins/smanager/phspark.py", line 95, in <lambda>
    self._rddWorkerList = self._rddWorkerList.map(lambda worker: _do_parallel_bulk(worker, task_dict))
  File "/media/sf_GitHub/TFG/pyomo/pyomo/solvers/plugins/smanager/phspark.py", line 88, in _do_parallel_bulk
    worker.process(task)
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/work/app-20180716180808-0261/0/phsolverserver.py", line 137, in process
    result = self._solver_server.process(data)
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/work/app-20180716180808-0261/0/phsolverserver.py", line 1367, in process
    data.release_cache)
  File "/home/crist/Downloads/spark-2.3.0-bin-hadoop2.7/work/app-20180716180808-0261/0/phsolverserver.py", line 1181, in restoreCachedSolutions
    _PHBase.restoreCachedSolutions(self, cache_id, release_cache)
  File "/media/sf_GitHub/TFG/pyomo/pyomo/pysp/ph.py", line 467, in restoreCachedSolutions
    % (cache_id))
RuntimeError: PH scenario tree solution cache with id 33555d9b-6f58-4ef7-b9cc-027e55a8257a does not exist

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more

2018-07-16 18:09:48 WARN  TaskSetManager:66 - Lost task 0.3 in stage 26.0 (TID 65, 10.0.2.15, executor 0): TaskKilled (Stage cancelled)
